{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived       False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age             True\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Cabin           True\n",
       "Embarked        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name','Cabin','Ticket','PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female',\n",
       "       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.get_dummies(train)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute age column with median\n",
    "train['Age'].fillna(train['Age'].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      False\n",
       "Pclass        False\n",
       "Age           False\n",
       "SibSp         False\n",
       "Parch         False\n",
       "Fare          False\n",
       "Sex_female    False\n",
       "Sex_male      False\n",
       "Embarked_C    False\n",
       "Embarked_Q    False\n",
       "Embarked_S    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop(['Survived'],axis=1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.scale(x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804\n",
      "Precision: 0.793\n",
      "Recall: 0.667\n",
      "F1 score: 0.724\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.637\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf2 = svm.SVC(C=0.001,gamma=0.0001)\n",
    "clf2.fit(x_train,y_train)\n",
    "y_pred2 = clf2.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred2),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred2),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred2),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred2),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.637\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf3 = svm.SVC(C=0.01,gamma=0.001)\n",
    "clf3.fit(x_train,y_train)\n",
    "y_pred3 = clf3.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred3),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred3),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred3),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred3),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.732\n",
      "Precision: 0.649\n",
      "Recall: 0.569\n",
      "F1 score: 0.607\n"
     ]
    }
   ],
   "source": [
    "clf4 = svm.SVC(C=0.5,gamma=0.01)\n",
    "clf4.fit(x_train,y_train)\n",
    "y_pred4 = clf4.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred4),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred4),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred4),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred4),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.821\n",
      "Precision: 0.884\n",
      "Recall: 0.585\n",
      "F1 score: 0.704\n"
     ]
    }
   ],
   "source": [
    "clf5 = svm.SVC(C=1,gamma=0.1)\n",
    "clf5.fit(x_train,y_train)\n",
    "y_pred5 = clf5.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred5),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred5),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred5),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred5),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804\n",
      "Precision: 0.857\n",
      "Recall: 0.554\n",
      "F1 score: 0.673\n"
     ]
    }
   ],
   "source": [
    "clf6 = svm.SVC(C=2,gamma=0.25)\n",
    "clf6.fit(x_train,y_train)\n",
    "y_pred6 = clf6.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred6),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred6),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred6),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred6),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.777\n",
      "Precision: 0.766\n",
      "Recall: 0.554\n",
      "F1 score: 0.643\n"
     ]
    }
   ],
   "source": [
    "clf7 = svm.SVC(C=5,gamma=0.5)\n",
    "clf7.fit(x_train,y_train)\n",
    "y_pred7 = clf7.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred7),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred7),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred7),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred7),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.788\n",
      "Precision: 0.755\n",
      "Recall: 0.615\n",
      "F1 score: 0.678\n"
     ]
    }
   ],
   "source": [
    "clf8 = svm.SVC(C=5,gamma=1)\n",
    "clf8.fit(x_train,y_train)\n",
    "y_pred8 = clf8.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test,y_pred8),3))\n",
    "print(\"Precision:\",round(metrics.precision_score(y_test,y_pred8),3))\n",
    "print(\"Recall:\",round(metrics.recall_score(y_test,y_pred8),3))\n",
    "print(\"F1 score:\",round(metrics.f1_score(y_test,y_pred8),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the model parameters by modifying the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('clf',\n",
       "                                        SVC(C=1, break_ties=False,\n",
       "                                            cache_size=200, class_weight=None,\n",
       "                                            coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma=0.1, kernel='rbf',\n",
       "                                            max_iter=-1, probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__C': (0.001, 0.01, 0.1, 0.5, 1, 2, 5),\n",
       "                         'clf__gamma': (0.0001, 0.001, 0.01, 0.1, 0.25, 0.5,\n",
       "                                        0.75, 1)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "#Setting up a ml pipeline\n",
    "pipeline = Pipeline([('clf', SVC(kernel = 'rbf', C = 1, gamma = 0.1))]) \n",
    "#Setting the parameters that shall be used during grid search\n",
    "params = {'clf__C':(0.001, 0.01, 0.1, 0.5, 1, 2, 5), \n",
    "          'clf__gamma':(0.0001, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1)} \n",
    "\n",
    "#Declaring the grid search to create several SVM ML in the pipeline each with all the declared parameters\n",
    "svm_grid_rbf = GridSearchCV(pipeline, params, n_jobs = -1,\n",
    "                            cv = 3, verbose = 0, scoring='accuracy') \n",
    "#Fitting the grid search ML with the training data\n",
    "svm_grid_rbf.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__C: \t 2\n",
      "\tclf__gamma: \t 0.1\n"
     ]
    }
   ],
   "source": [
    "#using .get_params() to identify the set of parameters that enabled the model to perform the best\n",
    "best = svm_grid_rbf.best_estimator_.get_params() \n",
    "\n",
    "for k in sorted(params.keys()): \n",
    "    print(f'\\t{k}: \\t {round(best[k], 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up the ML with parameters based on the Grid Search\n",
    "svc = SVC(C = 2, gamma = 0.10)\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predd = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.818\n",
      "Recall: 0.652\n",
      "F1 Score: 0.726\n"
     ]
    }
   ],
   "source": [
    "#Assessing the median Accuracy Scores\n",
    "print('Accuracy:', round(metrics.accuracy_score(y_test, y_predd), 3))\n",
    "print( 'Precision:', round(metrics.precision_score(y_test, y_predd), 3))\n",
    "print( 'Recall:', round(metrics.recall_score(y_test, y_predd), 3))\n",
    "print( 'F1 Score:', round(metrics.f1_score(y_test, y_predd), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tSVC(C=1,gamma=0.1)\tLogistic Regression(C=1)\n",
    "Accuracy\t82.10%\t           73%\n",
    "Precision\t88.40%\t           81.20%\n",
    "Recall\t    58.50%\t           63%\n",
    "F1 Score\t70.40%\t           71%\n",
    "\t\t\n",
    "** The logistic Regression model appears to be more sensitive than the SVC. Given that the recall and precision is higher, it would mean this model is able to identify relevant instances better and show that they are actually better.\t\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
